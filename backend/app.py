# -*- coding: utf-8 -*-  # ‡∏£‡∏∞‡∏ö‡∏∏ encoding ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå/‡∏™‡∏ï‡∏£‡∏¥‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢

"""
Flask Backend ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Market Basket Analysis ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡∏∞‡∏Å‡∏£‡πâ‡∏≤‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢ mlxtend library
"""  # ‚Üë docstring: ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ (‡πÅ‡∏°‡πâ‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏´‡∏∏‡πâ‡∏°‡∏î‡πâ‡∏ß‡∏¢ BasketAnalyzer ‡∏ó‡∏µ‡πà‡∏û‡∏∂‡πà‡∏á‡∏û‡∏≤ flexible_basket)

from flask import Flask, request, jsonify, send_file  # ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Flask ‡πÅ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á API/‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏Ç‡∏≠/‡∏ï‡∏≠‡∏ö JSON/‡∏™‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå
from flask_cors import CORS                           # ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ CORS ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏ß‡πá‡∏ö frontend ‡∏ï‡πà‡∏≤‡∏á origin ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API ‡πÑ‡∏î‡πâ
import pandas as pd                                   # ‡πÉ‡∏ä‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏£‡∏≤‡∏á
import numpy as np                                    # ‡πÉ‡∏ä‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç/‡∏ï‡∏£‡∏ß‡∏à NaN ‡πÉ‡∏ô‡∏ö‡∏≤‡∏á‡∏Å‡∏£‡∏ì‡∏µ
import json                                           # (‡∏™‡∏≥‡∏£‡∏≠‡∏á) ‡πÅ‡∏õ‡∏•‡∏á Python <-> JSON ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
import io                                             # (‡∏™‡∏≥‡∏£‡∏≠‡∏á) ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö‡∏™‡∏ï‡∏£‡∏µ‡∏° bytes ‡πÉ‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥
import os                                             # ‡πÉ‡∏ä‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå/‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå/‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á
from datetime import datetime                         # ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô ‡∏™‡∏£‡πâ‡∏≤‡∏á timestamp
import tempfile                                       # (‡∏™‡∏≥‡∏£‡∏≠‡∏á) ‡∏ó‡∏≥‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
from werkzeug.utils import secure_filename            # ‡∏ó‡∏≥‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡πâ‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏à‡∏≤‡∏Å input ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
import logging                                        # ‡∏£‡∏∞‡∏ö‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å log
import traceback                                      # ‡πÉ‡∏ä‡πâ‡∏û‡∏¥‡∏°‡∏û‡πå stack trace ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î

# Import data processor
from data_processors.basket_analyzer import BasketAnalyzer  # ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ñ‡∏•‡∏≤‡∏™‡∏ï‡∏±‡∏ß‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏´‡∏∏‡πâ‡∏° flexible_basket ‡πÉ‡∏´‡πâ‡∏°‡∏µ API ‡πÄ‡∏î‡∏¥‡∏°

# ‡∏™‡∏£‡πâ‡∏≤‡∏á Flask app
app = Flask(__name__)  # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏ô‡∏™‡πÅ‡∏ï‡∏ô‡∏ã‡πå‡πÅ‡∏≠‡∏õ Flask ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡∏î‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏£‡∏∞‡∏ö‡∏∏
CORS(app)              # ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô CORS ‡∏Å‡∏±‡∏ö‡πÅ‡∏≠‡∏õ (‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏ó‡∏∏‡∏Å‡πÇ‡∏î‡πÄ‡∏°‡∏ô)

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ logging
logging.basicConfig(level=logging.INFO)  # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏î‡∏±‡∏ö log ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡πÄ‡∏õ‡πá‡∏ô INFO (‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô info/warning/error)
logger = logging.getLogger(__name__)     # ‡∏™‡∏£‡πâ‡∏≤‡∏á logger ‡∏ï‡∏≤‡∏°‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏ô‡∏µ‡πâ

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô
app.config['MAX_CONTENT_LENGTH'] = 500 * 1024 * 1024  # 500MB  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
UPLOAD_FOLDER = 'uploads'                              # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á
ALLOWED_EXTENSIONS = {'xlsx', 'xls', 'csv'}           # ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå uploads
os.makedirs(UPLOAD_FOLDER, exist_ok=True)  # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ (‡πÑ‡∏°‡πà error ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß)

def allowed_file(filename):
    # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ True ‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏• ‡πÅ‡∏•‡∏∞‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def read_file_safely(filepath):
    """‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏î‡πâ‡∏ß‡∏¢ encoding ‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö"""
    try:
        if filepath.lower().endswith('.csv'):  # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV
            # ‡∏•‡∏≠‡∏á encoding ‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CSV ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏´‡∏•‡πà‡∏á
            encodings = ['utf-8', 'utf-8-sig', 'cp1252', 'iso-8859-1', 'tis-620', 'windows-1252']
            for encoding in encodings:
                try:
                    df = pd.read_csv(filepath, encoding=encoding)  # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏≠‡πà‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ encoding ‡∏ô‡∏µ‡πâ
                    print(f"‚úÖ ‡∏≠‡πà‡∏≤‡∏ô CSV ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏î‡πâ‡∏ß‡∏¢ encoding: {encoding}")   # log ‡∏™‡∏±‡πâ‡∏ô ‡πÜ
                    return df  # ‡∏ñ‡πâ‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏Ñ‡∏∑‡∏ô DataFrame ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
                except UnicodeDecodeError:
                    continue  # ‡∏ñ‡πâ‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ (‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô) ‡∏•‡∏≠‡∏á encoding ‡∏ï‡∏±‡∏ß‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
            
            # ‡∏ñ‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ chardet ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö encoding ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
            try:
                import chardet
                with open(filepath, 'rb') as f:
                    raw_data = f.read()                 # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö
                    detected = chardet.detect(raw_data) # ‡πÉ‡∏´‡πâ chardet ‡πÄ‡∏î‡∏≤ encoding
                    if detected['encoding']:
                        df = pd.read_csv(filepath, encoding=detected['encoding'])  # ‡∏≠‡πà‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ encoding ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö
                        print(f"‚úÖ ‡∏≠‡πà‡∏≤‡∏ô CSV ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏î‡πâ‡∏ß‡∏¢ detected encoding: {detected['encoding']}")
                        return df
            except:
                pass  # ‡∏ñ‡πâ‡∏≤ chardet ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡∏Å‡πá‡∏õ‡∏•‡πà‡∏≠‡∏¢‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏õ raise ‡∏Ç‡πâ‡∏≤‡∏á‡∏•‡πà‡∏≤‡∏á
                
        else:
            # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Excel (xlsx/xls)
            try:
                df = pd.read_excel(filepath, engine='openpyxl')  # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ openpyxl (‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö xlsx/xlsm)
                print("‚úÖ ‡∏≠‡πà‡∏≤‡∏ô Excel ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏î‡πâ‡∏ß‡∏¢ openpyxl")
                return df
            except:
                try:
                    df = pd.read_excel(filepath, engine='xlrd')  # ‡∏™‡∏≥‡∏£‡∏≠‡∏á: xlrd (‡∏ö‡∏≤‡∏á‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö xls ‡πÄ‡∏Å‡πà‡∏≤)
                    print("‚úÖ ‡∏≠‡πà‡∏≤‡∏ô Excel ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏î‡πâ‡∏ß‡∏¢ xlrd")
                    return df
                except:
                    pass  # ‡∏ñ‡πâ‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡πÅ‡∏ö‡∏ö ‡πÉ‡∏´‡πâ‡πÑ‡∏õ raise ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á
        
        raise Exception("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ")  # ‡∏ñ‡πâ‡∏≤‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÅ‡∏•‡πâ‡∏ß‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î
        
    except Exception as e:
        # ‡∏´‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏≠‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ/‡∏ù‡∏±‡πà‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏Å
        raise Exception(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå: {str(e)}")

def create_download_files(results, filename):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î - ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Excel ‡πÅ‡∏•‡∏∞ CSV"""
    try:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')  # ‡∏ï‡∏µ‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏ä‡∏ô‡∏Å‡∏±‡∏ô
        base_name = filename.rsplit('.', 1)[0] if '.' in filename else filename  # ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏°‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•
        
        output_files = {}  # ‡πÄ‡∏Å‡πá‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏î‡πâ
        
        # 1. Excel File - Complete Report
        excel_filename = f"basket_analysis_{base_name}_{timestamp}.xlsx"  # ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô Excel
        excel_filepath = os.path.join(UPLOAD_FOLDER, excel_filename)       # path ‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå uploads
        
        with pd.ExcelWriter(excel_filepath, engine='openpyxl') as writer:  # ‡πÄ‡∏õ‡∏¥‡∏î writer ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Excel
            # Summary sheet (‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏£‡∏ß‡∏°)
            summary_data = {
                'Metric': ['Analysis Type', 'Original File', 'Generated At', 'Total Rules', 'Total Transactions', 'Total Items'],
                'Value': [
                    'Market Basket Analysis',                 # ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
                    filename,                                 # ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á
                    datetime.now().strftime('%Y-%m-%d %H:%M:%S'),  # ‡πÄ‡∏ß‡∏•‡∏≤‡∏≠‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå
                    results.get('totalRules', 0),            # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏é‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                    results.get('totalTransactions', 0),     # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                    results.get('totalItems', 0)             # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥
                ]
            }
            pd.DataFrame(summary_data).to_excel(writer, sheet_name='Summary', index=False)  # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ä‡∏µ‡∏ï Summary
            
            # All Association Rules (‡∏ó‡∏∏‡∏Å‡∏Å‡∏é‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå)
            if 'rulesTable' in results and results['rulesTable']:
                rules_df = pd.DataFrame(results['rulesTable'])         # ‡πÅ‡∏õ‡∏•‡∏á‡∏•‡∏¥‡∏™‡∏ï‡πå dict ‚Üí DataFrame
                rules_df.to_excel(writer, sheet_name='Association Rules', index=False)  # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ä‡∏µ‡∏ï Rules
            
            # Single Item Rules (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
            if 'singleRulesTable' in results and results['singleRulesTable']:
                single_rules_df = pd.DataFrame(results['singleRulesTable'])
                single_rules_df.to_excel(writer, sheet_name='Single Item Rules', index=False)  # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ä‡∏µ‡∏ï Single
            
            # Frequent Itemsets
            if 'frequentItemsetsTable' in results and results['frequentItemsetsTable']:
                frequent_df = pd.DataFrame(results['frequentItemsetsTable'])
                frequent_df.to_excel(writer, sheet_name='Frequent Itemsets', index=False)  # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ä‡∏µ‡∏ï Itemsets
        
        output_files['excel'] = excel_filename  # ‡∏à‡∏î‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå Excel ‡πÑ‡∏ß‡πâ‡πÉ‡∏´‡πâ‡∏ù‡∏±‡πà‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÇ‡∏´‡∏•‡∏î
        
        # 2. CSV File - Association Rules (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Å‡∏é)
        csv_filename = f"association_rules_{base_name}_{timestamp}.csv"  # ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå CSV
        csv_filepath = os.path.join(UPLOAD_FOLDER, csv_filename)         # path ‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á
        
        if 'rulesTable' in results and results['rulesTable']:
            rules_df = pd.DataFrame(results['rulesTable'])
            rules_df.to_csv(csv_filepath, index=False, encoding='utf-8-sig')  # CSV ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ô Excel ‡πÑ‡∏î‡πâ‡∏î‡∏µ (‡∏°‡∏µ BOM)
        
        output_files['csv'] = csv_filename  # ‡∏à‡∏î‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå CSV
        
        return True, output_files  # ‡∏™‡πà‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à + ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ
        
    except Exception as e:
        print(f"‚ùå Error creating download files: {str(e)}")  # log ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Å‡∏£‡∏ì‡∏µ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß
        return False, str(e)                                  # ‡∏™‡πà‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß + ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° error

@app.route('/api/health', methods=['GET'])
def health_check():
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Ç‡∏≠‡∏á API"""
    # ‡∏™‡πà‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÉ‡∏´‡πâ frontend ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ API ‡∏¢‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥‡πÑ‡∏´‡∏°
    return jsonify({
        'status': 'healthy',                      # ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡∏∞‡∏ö‡∏ö
        'timestamp': datetime.now().isoformat(),  # ‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô (ISO 8601)
        'message': 'Market Basket Analysis API is running successfully'  # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ö‡∏≠‡∏Å‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
    })

@app.route('/api/upload', methods=['POST'])
def upload_file():
    """‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel/CSV ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô JSON"""
    try:
        print("üìÅ Received upload request")  # log ‡∏ù‡∏±‡πà‡∏á‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏Ç‡∏≠‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
        
        if 'file' not in request.files:  # ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå 'file' ‡πÉ‡∏ô‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏°‡∏±‡πâ‡∏¢
            return jsonify({'error': 'No file provided'}), 400  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö 400
        
        file = request.files['file']  # ‡∏î‡∏∂‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏Ç‡∏≠
        if file.filename == '':       # ‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ß‡πà‡∏≤‡∏á
            return jsonify({'error': 'No file selected'}), 400
        
        if not allowed_file(file.filename):  # ‡∏ï‡∏£‡∏ß‡∏à‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏ß‡πà‡∏≤‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÑ‡∏´‡∏°
            return jsonify({'error': 'File type not allowed. Please upload Excel or CSV files.'}), 400
        
        print(f"üìÑ Processing file: {file.filename}")  # log ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏•‡∏á‡∏î‡∏¥‡∏™‡∏Å‡πå
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')            # ‡∏ó‡∏≥ prefix ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏±‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏ã‡πâ‡∏≥
        filename = f"{timestamp}_{secure_filename(file.filename)}"       # ‡∏ó‡∏≥‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡πâ‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
        filepath = os.path.join(UPLOAD_FOLDER, filename)                 # ‡∏™‡∏£‡πâ‡∏≤‡∏á path ‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á
        file.save(filepath)                                              # ‡πÄ‡∏ã‡∏ü‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏£‡∏¥‡∏á‡∏•‡∏á‡∏î‡∏¥‡∏™‡∏Å‡πå
        
        print(f"‚úÖ File saved as: {filename}")  # log ‡∏ß‡πà‡∏≤‡πÄ‡∏ã‡∏ü‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢
        
        # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏õ‡πá‡∏ô DataFrame (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢ encoding/engine ‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå)
        df = read_file_safely(filepath)
        
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢: ‡πÅ‡∏ó‡∏ô NaN ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á‡∏ß‡πà‡∏≤‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
        df = df.fillna('')
        
        # ‡πÅ‡∏õ‡∏•‡∏á DataFrame ‡πÄ‡∏õ‡πá‡∏ô list-of-lists ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö frontend ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (preview)
        headers = [str(col) for col in df.columns.tolist()]  # ‡πÅ‡∏õ‡∏•‡∏á‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        rows = []                                            # ‡∏à‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡πÅ‡∏ñ‡∏ß‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        
        # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏û‡∏£‡∏µ‡∏ß‡∏¥‡∏ß (‡∏•‡∏î‡∏†‡∏≤‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢/‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå)
        display_df = df.head(1000)  # ‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 1000 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å
        
        for _, row in display_df.iterrows():  # ‡∏ß‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏µ‡∏•‡∏∞‡πÅ‡∏ñ‡∏ß
            row_data = []
            for value in row:                 # ‡∏ß‡∏ô‡∏ú‡πà‡∏≤‡∏ô‡∏ó‡∏∏‡∏Å‡πÄ‡∏ã‡∏•‡∏•‡πå‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ô‡∏±‡πâ‡∏ô
                if pd.isna(value) or value is None:
                    row_data.append('')       # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô NaN/None ‚Üí ‡πÅ‡∏ó‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏á
                else:
                    row_data.append(str(value))  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô JSON ‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢
            rows.append(row_data)             # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏ñ‡∏ß‡∏•‡∏á‡∏•‡∏¥‡∏™‡∏ï‡πå
        
        data = [headers] + rows  # ‡∏£‡∏ß‡∏° header + rows ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡πâ‡∏≠‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö frontend
        
        print(f"‚úÖ File processed successfully. Total rows: {len(df)}, Display rows: {len(rows)}, Columns: {len(headers)}")
        # ‚Üë log ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÇ‡∏î‡∏¢‡∏¢‡πà‡∏≠
        
        response_data = {
            'success': True,                         # ‡∏ò‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
            'filename': filename,                    # ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏ã‡∏ü‡πÑ‡∏ß‡πâ (‡πÉ‡∏´‡πâ frontend ‡πÉ‡∏ä‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å process ‡∏ï‡πà‡∏≠)
            'data': data,                            # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (header + 1000 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å)
            'rows': len(df),                         # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏£‡∏¥‡∏á
            'columns': len(headers),                 # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
            'column_names': headers,                 # ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
            'file_size': os.path.getsize(filepath)   # ‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ö‡∏ï‡πå
        }
        
        return jsonify(response_data)  # ‡∏™‡πà‡∏á JSON ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÉ‡∏´‡πâ UI
        
    except Exception as e:
        logger.error(f"Upload error: {str(e)}")             # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô log error
        print(f"‚ùå Upload error: {str(e)}")                 # ‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ô‡∏Ñ‡∏≠‡∏ô‡πÇ‡∏ã‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏µ‡∏ö‡∏±‡∏Å
        return jsonify({'error': f'Upload failed: {str(e)}'}), 500  # ‡∏ï‡∏≠‡∏ö 500 ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°

@app.route('/api/process', methods=['POST'])
def process_data():
    """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• Market Basket Analysis"""
    try:
        print("üîÑ Starting Market Basket Analysis...")  # log ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        data = request.get_json()                      # ‡∏£‡∏±‡∏ö payload JSON ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏Ç‡∏≠ POST
        
        if not data:                                   # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ payload
            return jsonify({'error': 'No data provided'}), 400
        
        filename = data.get('filename')                # ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå (‡∏ó‡∏µ‡πà‡πÄ‡∏ã‡∏ü‡πÑ‡∏ß‡πâ‡πÉ‡∏ô /uploads ‡∏ï‡∏≠‡∏ô‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î)
        selected_columns = data.get('selectedColumns', [])  # ‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (optional)
        
        print(f"üìä Processing: {filename}, Columns: {len(selected_columns)}")  # log ‡∏ö‡∏≠‡∏Å‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå
        
        if not filename:                               # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏≤ ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏ï‡πà‡∏≠‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
            return jsonify({'error': 'Missing filename'}), 400
        
        # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ‡∏à‡∏≤‡∏Å‡∏î‡∏¥‡∏™‡∏Å‡πå
        filepath = os.path.join(UPLOAD_FOLDER, filename)  # path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
        if not os.path.exists(filepath):                  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß (‡∏ñ‡∏π‡∏Å‡∏•‡∏ö/‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏)
            return jsonify({'error': 'File not found'}), 404
        
        # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        df = read_file_safely(filepath)
        print(f"‚úÖ File read successfully. Shape: {df.shape}")  # log ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (‡∏ñ‡πâ‡∏≤‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ß‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏î‡∏±‡∏ä‡∏ô‡∏µ)
        if selected_columns:
            try:
                selected_df = df.iloc[:, selected_columns]  # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå (list ‡∏Ç‡∏≠‡∏á index)
                print(f"üìã Selected columns: {selected_df.columns.tolist()}")  # log ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á
            except IndexError:
                return jsonify({'error': 'Selected columns are out of range'}), 400  # ‡∏Å‡∏£‡∏ì‡∏µ index ‡∏ú‡∏¥‡∏î‡∏ä‡πà‡∏ß‡∏á
        else:
            selected_df = df  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏ ‚Üí ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á
        
        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• Market Basket Analysis ‡∏î‡πâ‡∏ß‡∏¢ BasketAnalyzer (‡∏´‡∏∏‡πâ‡∏° flexible_basket)
        print(f"‚öôÔ∏è Running Market Basket Analysis...")
        analyzer = BasketAnalyzer(min_support=0.001, min_lift=1.0)  # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
        results = analyzer.analyze_basket(selected_df, df)          # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô dict ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ
        
        if not results.get('success'):  # ‡∏´‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß (‡πÄ‡∏ä‡πà‡∏ô df ‡∏ß‡πà‡∏≤‡∏á/‡∏à‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ)
            return jsonify({'error': results.get('error', 'Analysis failed')}), 500
        
        print("‚úÖ Analysis completed")  # log ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Excel+CSV) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
        print("üíæ Creating download files...")
        success, output_files = create_download_files(results, filename)
        
        if not success:
            # ‡∏ñ‡πâ‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö/‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô ‡∏Å‡πá‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á outputFiles ‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ
            print(f"‚ö†Ô∏è Warning: Could not create all download files: {output_files}")
            output_files = {}
        
        print("üéâ Processing completed successfully")  # log ‡∏à‡∏ö‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        
        return jsonify({
            'success': True,                         # ‡∏ò‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
            'analysisType': 'basket',                # ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ä‡∏ô‡∏¥‡∏î‡∏≠‡∏∑‡πà‡∏ô‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï)
            'selectedColumns': selected_columns,     # ‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
            'results': results,                      # ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏ï‡πá‡∏°‡∏à‡∏≤‡∏Å BasketAnalyzer (rulesTable/fiTable/meta/‡∏™‡∏£‡∏∏‡∏õ)
            'outputFiles': output_files,             # ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î (excel/csv) ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå uploads
            'summary': {                             # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö UI
                'totalRows': len(df),                # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                'processedRows': len(selected_df),   # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏£‡∏¥‡∏á
                'selectedColumns': len(selected_columns) if selected_columns else len(df.columns),  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ
                'totalColumns': len(df.columns),     # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                'processingTime': 'Completed',       # (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á) ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ (‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ß‡∏±‡∏î‡∏à‡∏£‡∏¥‡∏á)
                'completedAt': datetime.now().isoformat()  # ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏£‡πá‡∏à‡∏á‡∏≤‡∏ô
            }
        })
        
    except Exception as e:
        logger.error(f"Processing error: {str(e)}")  # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å error ‡∏•‡∏á logger
        print(f"‚ùå Processing error: {str(e)}")      # ‡∏û‡∏¥‡∏°‡∏û‡πå error ‡∏ö‡∏ô‡∏Ñ‡∏≠‡∏ô‡πÇ‡∏ã‡∏•
        traceback.print_exc()                        # ‡πÅ‡∏™‡∏î‡∏á stack trace ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏µ‡∏ö‡∏±‡∏Å
        return jsonify({'error': f'Processing failed: {str(e)}'}), 500  # ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ 500 ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°

@app.route('/api/download/<format>/<filename>', methods=['GET'])
def download_file(format, filename):
    """‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå"""
    try:
        filepath = os.path.join(UPLOAD_FOLDER, filename)  # ‡∏™‡∏£‡πâ‡∏≤‡∏á path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏£‡πâ‡∏≠‡∏á‡∏Ç‡∏≠
        if not os.path.exists(filepath):                  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡∏î‡∏¥‡∏™‡∏Å‡πå
            return jsonify({'error': 'File not found'}), 404
        
        return send_file(filepath, as_attachment=True)    # ‡∏™‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡πâ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏ô‡∏ö
        
    except Exception as e:
        logger.error(f"Download error: {str(e)}")         # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å error ‡∏Å‡∏£‡∏ì‡∏µ‡∏™‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß
        return jsonify({'error': f'Download failed: {str(e)}'}), 500  # ‡∏ï‡∏≠‡∏ö 500 ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°

# ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤
def cleanup_old_files():
    """‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÄ‡∏Å‡∏¥‡∏ô 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á"""
    try:
        current_time = datetime.now().timestamp()  # ‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÉ‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (epoch)
        max_age = 3600  # 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á (‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
        
        for filename in os.listdir(UPLOAD_FOLDER):        # ‡πÑ‡∏•‡πà‡∏î‡∏π‡∏ó‡∏∏‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå uploads
            filepath = os.path.join(UPLOAD_FOLDER, filename)
            if os.path.isfile(filepath):                  # ‡∏™‡∏ô‡πÉ‡∏à‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‚Äú‡πÑ‡∏ü‡∏•‡πå‚Äù ‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏°‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
                file_age = current_time - os.path.getmtime(filepath)  # ‡∏≠‡∏≤‡∏¢‡∏∏‡πÑ‡∏ü‡∏•‡πå = ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô - ‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
                if file_age > max_age:                    # ‡∏ñ‡πâ‡∏≤‡∏≠‡∏≤‡∏¢‡∏∏‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
                    os.remove(filepath)                   # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏¥‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà
                    print(f"üóëÔ∏è Deleted old file: {filename}")  # log ‡∏ß‡πà‡∏≤‡∏•‡∏ö‡πÅ‡∏•‡πâ‡∏ß
    except Exception as e:
        print(f"‚ö†Ô∏è Cleanup error: {str(e)}")              # log ‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ñ‡πâ‡∏≤‡∏•‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß

if __name__ == '__main__':  # ‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ñ‡∏π‡∏Å import)
    print("üöÄ Starting Market Basket Analysis Server...")             # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
    print("üõí Market Basket Analysis API is ready!")                 # ‡πÅ‡∏à‡πâ‡∏á‡∏ß‡πà‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£
    print("üåê Frontend can connect to: http://localhost:5000")       # URL ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏à‡∏≤‡∏Å frontend
    print("üìÅ Upload folder:", UPLOAD_FOLDER)                        # ‡πÅ‡∏™‡∏î‡∏á path ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
    
    # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤
    cleanup_old_files()                                              # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏≠‡∏≠‡∏Å‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå
    
    # ‡∏£‡∏±‡∏ô‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå Flask
    app.run(debug=True, host='0.0.0.0', port=5000)                   # ‡∏£‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Æ‡∏™‡∏ï‡πå 0.0.0.0 ‡∏û‡∏≠‡∏£‡πå‡∏ï 5000 ‡πÄ‡∏õ‡∏¥‡∏î debug mode
